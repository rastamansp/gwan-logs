# Gwan APM - Sistema de Observabilidade Completa

Sistema de observabilidade completa para aplica√ß√µes Node.js e Python rodando no Portainer, utilizando Elasticsearch, Logstash, Kibana, OpenTelemetry, Jaeger e Prometheus para monitoramento, logs e traces distribu√≠dos.

## üèóÔ∏è Arquitetura

```mermaid
graph TB
    A[Aplica√ß√µes<br/>Node.js/Python] --> B[OpenTelemetry<br/>Collector]
    B --> C[Logstash<br/>Processamento]
    B --> D[Prometheus<br/>M√©tricas]
    B --> E[Jaeger<br/>Traces]
    C --> F[Elasticsearch<br/>Armazenamento]
    D --> G[Kibana<br/>Visualiza√ß√£o]
    E --> G
    F --> G
    
    style A fill:#e1f5fe
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e8
    style E fill:#fff8e1
    style F fill:#fce4ec
    style G fill:#e0f2f1
```

## üîç Observabilidade Completa

### APM (Application Performance Management)
O sistema evoluiu de um simples sistema de logs para um **APM completo** que oferece:

#### üìä **M√©tricas (Metrics)**
- **Contadores**: Total de requisi√ß√µes, erros, opera√ß√µes
- **Histogramas**: Dura√ß√£o de requisi√ß√µes, lat√™ncia
- **Gauges**: Uso de mem√≥ria, CPU, conex√µes ativas
- **Auto-instrumenta√ß√£o**: M√©tricas autom√°ticas do sistema

#### üîó **Traces (Rastreamento Distribu√≠do)**
- **Spans distribu√≠dos**: Rastreamento de requisi√ß√µes entre servi√ßos
- **Contexto distribu√≠do**: Propaga√ß√£o de contexto entre aplica√ß√µes
- **Lat√™ncia**: Medi√ß√£o de tempo de resposta
- **Depend√™ncias**: Mapeamento de chamadas entre servi√ßos

#### üìù **Logs Estruturados**
- **Correla√ß√£o**: Logs vinculados a traces via TraceId/SpanId
- **Formato JSON**: Logs estruturados e padronizados
- **Filtros**: Remo√ß√£o autom√°tica de dados sens√≠veis
- **Enriquecimento**: Adi√ß√£o de metadados autom√°ticos

### Fluxo de Dados APM

```mermaid
flowchart LR
    A[Aplica√ß√£o<br/>Node.js/Python] --> B[üìù Logs]
    A --> C[üîç Traces]
    A --> D[üìà Metrics]
    A --> E[üìä Telemetria]
    
    B --> F[Logstash]
    C --> G[OpenTelemetry<br/>Collector]
    D --> G
    E --> G
    
    F --> H[Elasticsearch]
    G --> I[Jaeger]
    G --> J[Prometheus]
    G --> F
    
    H --> K[Kibana]
    I --> K
    J --> K
    
    style A fill:#e1f5fe
    style F fill:#f3e5f5
    style G fill:#fff3e0
    style H fill:#fce4ec
    style I fill:#fff8e1
    style J fill:#e8f5e8
    style K fill:#e0f2f1
```

### Sequ√™ncia de uma Requisi√ß√£o HTTP

```mermaid
sequenceDiagram
    participant Client
    participant App as Aplica√ß√£o Node.js
    participant OTEL as OpenTelemetry Collector
    participant LS as Logstash
    participant ES as Elasticsearch
    participant J as Jaeger
    participant P as Prometheus
    participant K as Kibana

    Client->>App: HTTP Request
    App->>App: Criar Span (TraceId: abc123)
    App->>OTEL: Enviar Trace
    App->>OTEL: Enviar Metrics
    App->>LS: Enviar Log (TraceId: abc123)
    
    OTEL->>J: Armazenar Trace
    OTEL->>P: Armazenar Metrics
    OTEL->>LS: Enviar Logs OTLP
    
    LS->>ES: Indexar Logs
    ES->>K: Disponibilizar dados
    J->>K: Disponibilizar traces
    P->>K: Disponibilizar metrics
    
    Note over K: Correla√ß√£o via TraceId
```

### Arquitetura de Rede

```mermaid
graph TB
    subgraph "Rede Externa"
        T[Traefik<br/>Load Balancer]
    end
    
    subgraph "Rede Docker 'gwan'"
        subgraph "Stack Gwan APM"
            ES[Elasticsearch<br/>9200]
            K[Kibana<br/>5601]
            LS[Logstash<br/>5044/9600]
            OTEL[OpenTelemetry<br/>4318/8888]
            J[Jaeger<br/>16686]
            P[Prometheus<br/>9090]
        end
    end
    
    T --> ES
    T --> K
    T --> LS
    T --> OTEL
    T --> J
    T --> P
    
    style T fill:#ffebee
    style ES fill:#fce4ec
    style K fill:#e0f2f1
    style LS fill:#f3e5f5
    style OTEL fill:#fff3e0
    style J fill:#fff8e1
    style P fill:#e8f5e8
```

## üìã Pr√©-requisitos

- Docker e Docker Compose instalados
- Portainer configurado
- Acesso ao servidor (69.62.99.103)
- Aproximadamente 15GB de espa√ßo em disco para logs e telemetria
- Node.js 16+ para aplica√ß√µes com OpenTelemetry

## üöÄ Instala√ß√£o

### 1. Clone o reposit√≥rio
```bash
git clone https://github.com/seu-usuario/gwan-logs.git
cd gwan-logs
```

### 2. Configure as vari√°veis de ambiente
```bash
cp .env.example .env
# Edite o arquivo .env com suas configura√ß√µes
```

### 3. Deploy via Portainer
1. Acesse o Portainer
2. V√° em "Stacks" ‚Üí "Add stack"
3. Nome: `gwan-logs`
4. Cole o conte√∫do do arquivo `docker-compose.yml`
5. Clique em "Deploy the stack"

### 4. Acesse as interfaces
- **üìä Kibana**: `https://kibana.gwan.com.br` (Logs e Visualiza√ß√£o)
- **üîç Jaeger**: `https://jaeger.gwan.com.br` (Traces e Spans)
- **üìä Prometheus**: `https://prometheus.gwan.com.br` (M√©tricas)
- **üö® Alertmanager**: `https://alertmanager.gwan.com.br` (Alertas Cr√≠ticos)
- **üîß OpenTelemetry Collector**: `https://otel.gwan.com.br` (Status)
- **üìù Logstash**: `https://logstash.gwan.com.br` (Status)
- **üóÑÔ∏è Elasticsearch**: `https://elasticsearch.gwan.com.br` (API REST)

## üìä Monitoramento e Alertas

### Alertas Configurados
O sistema monitora apenas alertas cr√≠ticos de disponibilidade:

- **Elasticsearch Down**: Servi√ßo de armazenamento indispon√≠vel
- **Kibana Down**: Interface de visualiza√ß√£o indispon√≠vel  
- **Prometheus Down**: Coletor de m√©tricas indispon√≠vel
- **OpenTelemetry Collector Down**: Coletor de telemetria indispon√≠vel

### M√©tricas Dispon√≠veis
- **Aplica√ß√£o**: Requisi√ß√µes, erros, lat√™ncia (via Prometheus)
- **Sistema**: Health checks dos servi√ßos
- **Logs**: An√°lise completa via Kibana
- **Traces**: Rastreamento distribu√≠do via Jaeger

## üîß Configura√ß√£o das Aplica√ß√µes

### Para aplica√ß√µes Node.js com OpenTelemetry

#### 1. Instalar depend√™ncias
```bash
npm install @opentelemetry/sdk-node @opentelemetry/auto-instrumentations-node @opentelemetry/exporter-trace-otlp-http @opentelemetry/exporter-metrics-otlp-http winston winston-elasticsearch
```

#### 2. Configurar OpenTelemetry
```javascript
const { NodeSDK } = require('@opentelemetry/sdk-node');
const { getNodeAutoInstrumentations } = require('@opentelemetry/auto-instrumentations-node');
const { OTLPTraceExporter } = require('@opentelemetry/exporter-trace-otlp-http');
const { OTLPMetricExporter } = require('@opentelemetry/exporter-metrics-otlp-http');
const { Resource } = require('@opentelemetry/resources');
const { SemanticResourceAttributes } = require('@opentelemetry/semantic-conventions');
const { PeriodicExportingMetricReader } = require('@opentelemetry/sdk-metrics');

// Configura√ß√£o do OpenTelemetry
const sdk = new NodeSDK({
  resource: new Resource({
    [SemanticResourceAttributes.SERVICE_NAME]: 'minha-app',
    [SemanticResourceAttributes.SERVICE_VERSION]: '1.0.0',
    environment: 'production',
  }),
  traceExporter: new OTLPTraceExporter({
    url: 'http://localhost:4318/v1/traces',
  }),
  metricReader: new PeriodicExportingMetricReader({
    exporter: new OTLPMetricExporter({
      url: 'http://localhost:4318/v1/metrics',
    }),
    exportIntervalMillis: 1000,
  }),
  instrumentations: [getNodeAutoInstrumentations()],
});

// Inicializa o SDK
sdk.start();
```

#### 3. Configurar Logger com Winston
```javascript
const winston = require('winston');
const { ElasticsearchTransport } = require('winston-elasticsearch');
const { trace } = require('@opentelemetry/api');

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console(),
    new ElasticsearchTransport({
      level: 'info',
      clientOpts: {
        node: 'http://elasticsearch:9200',
        index: 'gwan-logs'
      }
    })
  ]
});

// Middleware para Express com OpenTelemetry
const loggerMiddleware = (req, res, next) => {
  const start = Date.now();
  const tracer = trace.getTracer('minha-app');
  
  const span = tracer.startSpan('http-request', {
    attributes: {
      'http.method': req.method,
      'http.url': req.url,
      'http.user_agent': req.get('User-Agent'),
    }
  });
  
  res.on('finish', () => {
    const duration = Date.now() - start;
    
    span.setAttributes({
      'http.status_code': res.statusCode,
      'http.response_size': res.get('Content-Length'),
    });
    
    logger.info('HTTP Request', {
      method: req.method,
      url: req.url,
      status: res.statusCode,
      duration: `${duration}ms`,
      traceId: span.spanContext().traceId,
      spanId: span.spanContext().spanId,
    });
    
    span.end();
  });
  
  next();
};
```

### Para aplica√ß√µes Python com OpenTelemetry

#### 1. Instalar depend√™ncias
```bash
pip install opentelemetry-api opentelemetry-sdk opentelemetry-instrumentation-flask opentelemetry-exporter-otlp-proto-http python-json-logger elasticsearch
```

#### 2. Configurar OpenTelemetry
```python
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.resources import Resource
from opentelemetry.instrumentation.flask import FlaskInstrumentor

# Configurar o provider de traces
resource = Resource.create({"service.name": "minha-app", "service.version": "1.0.0"})
trace.set_tracer_provider(TracerProvider(resource=resource))

# Configurar o exportador
otlp_exporter = OTLPSpanExporter(endpoint="http://localhost:4318/v1/traces")
span_processor = BatchSpanProcessor(otlp_exporter)
trace.get_tracer_provider().add_span_processor(span_processor)

# Instrumentar Flask
FlaskInstrumentor().instrument()
```

## üìä Visualiza√ß√£o de Dados

### Kibana - Interface Principal
- **Discover**: Pesquisa e an√°lise de logs
- **Dashboards**: Visualiza√ß√µes customizadas
- **Index Patterns**: Configura√ß√£o de √≠ndices
- **Alertas**: Configura√ß√£o de alertas baseados em logs
- **M√©tricas**: Visualiza√ß√µes de performance

### Jaeger - Distributed Tracing
- **Search**: Busca de traces por servi√ßo, opera√ß√£o, tags
- **Trace View**: Visualiza√ß√£o detalhada de traces
- **Dependencies**: Mapa de depend√™ncias entre servi√ßos
- **Metrics**: M√©tricas de lat√™ncia e throughput

### Prometheus - M√©tricas B√°sicas
- **Time-series**: Dados hist√≥ricos de performance
- **Query Language**: PromQL para consultas avan√ßadas
- **Alertas**: Alertas cr√≠ticos de disponibilidade
- **Health Checks**: Status dos servi√ßos

### Alertmanager - Gest√£o de Alertas
- **Agrupamento**: Agrupa alertas similares
- **Supress√£o**: Suprime alertas menores quando h√° problemas cr√≠ticos
- **Notifica√ß√µes**: Distribui alertas pelos canais configurados

## üîí Seguran√ßa

- **Autentica√ß√£o**: Credenciais configur√°veis
- **TLS/SSL**: Suporte a HTTPS
- **Filtros**: Remo√ß√£o autom√°tica de dados sens√≠veis
- **Isolamento**: Rede Docker isolada
- **Backup**: Backup autom√°tico dos dados

## üìà Escalabilidade

O sistema APM foi projetado para:
- **Aplica√ß√µes**: Suportar at√© 100 aplica√ß√µes simult√¢neas
- **Logs**: Processar 50.000 logs por minuto
- **Traces**: Rastrear 10.000 traces por minuto
- **M√©tricas**: Coletar 1.000 m√©tricas por segundo
- **Armazenamento**: 90 dias de reten√ß√£o configur√°vel
- **Backup**: Backup autom√°tico di√°rio
- **Performance**: Lat√™ncia < 100ms para consultas
- **Disponibilidade**: 99.9% uptime

## üõ†Ô∏è Manuten√ß√£o

### Backup
```bash
# Backup do Elasticsearch
docker exec gwan-elasticsearch elasticsearch-dump --input=http://localhost:9200/gwan-logs --output=backup-logs.json

# Backup das configura√ß√µes
docker cp gwan-otel-collector:/etc/otel-collector-config.yaml ./backup/otel-config.yaml
```

### Limpeza de Dados Antigos
Configure pol√≠ticas de reten√ß√£o:
- **Logs**: 30-90 dias (configur√°vel)
- **Traces**: 7-30 dias (configur√°vel)
- **M√©tricas**: 90-365 dias (configur√°vel)

### Monitoramento do Sistema
- **CPU**: < 80% por container
- **Mem√≥ria**: < 85% por container
- **Disco**: < 90% total
- **Rede**: < 1Gbps por servi√ßo

## üêõ Troubleshooting

### Problemas Comuns

#### 1. OpenTelemetry Collector n√£o inicia
```bash
# Verificar logs
docker logs gwan-otel-collector

# Verificar configura√ß√£o
docker exec gwan-otel-collector cat /etc/otel-collector-config.yaml

# Verificar conectividade
curl http://localhost:4318/health
```

#### 2. Traces n√£o aparecem no Jaeger
```bash
# Verificar se o Collector est√° recebendo dados
curl http://localhost:4318/v1/traces

# Verificar conectividade com Jaeger
curl http://jaeger:16686/api/services

# Verificar configura√ß√£o OTLP
docker logs gwan-jaeger
```

#### 3. M√©tricas n√£o s√£o coletadas
```bash
# Verificar endpoint de m√©tricas
curl http://localhost:8888/metrics

# Verificar configura√ß√£o do Prometheus
docker logs gwan-prometheus

# Verificar targets no Prometheus
curl http://localhost:9090/api/v1/targets

# Verificar conectividade da aplica√ß√£o
telnet localhost 4318
```

#### 4. Prometheus sem dados
```bash
# Verificar status do Prometheus
curl http://localhost:9090/-/healthy

# Verificar targets
curl http://localhost:9090/api/v1/targets

# Verificar configura√ß√£o
docker exec gwan-prometheus cat /etc/prometheus/prometheus.yml

# Verificar logs
docker logs gwan-prometheus
```

#### 4. Logs n√£o aparecem no Kibana
```bash
# Verificar Elasticsearch
curl http://localhost:9200/_cluster/health

# Verificar Logstash
docker logs gwan-logstash

# Verificar √≠ndices
curl http://localhost:9200/_cat/indices
```

#### 5. Alertmanager n√£o envia alertas
```bash
# Verificar status do Alertmanager
curl http://localhost:9093/-/healthy

# Verificar configura√ß√£o
docker exec gwan-alertmanager cat /etc/alertmanager/alertmanager.yml

# Verificar logs
docker logs gwan-alertmanager

# Verificar conectividade com Prometheus
curl http://localhost:9090/api/v1/alertmanagers
```

### Logs do Sistema
```bash
# Logs do OpenTelemetry Collector
docker logs gwan-otel-collector

# Logs do Jaeger
docker logs gwan-jaeger

# Logs do Prometheus
docker logs gwan-prometheus

# Logs do Alertmanager
docker logs gwan-alertmanager

# Logs do Elasticsearch
docker logs gwan-elasticsearch

# Logs do Logstash
docker logs gwan-logstash

# Logs do Kibana
docker logs gwan-kibana
```

## üìû Suporte

Para suporte t√©cnico:
- **GitHub Issues**: [Abrir Issue](link-para-issues)
- **Email**: suporte@gwan.com.br
- **Documenta√ß√£o**: [Wiki do Projeto](link-para-wiki)
- **Telegram**: @gwan_suporte

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

**Desenvolvido para Gwan.com.br** üöÄ
